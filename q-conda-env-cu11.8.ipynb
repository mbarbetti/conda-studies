{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61cdba29-88bc-4208-952c-0c388cc280db",
   "metadata": {},
   "source": [
    "# Quantum `conda` environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8fa78a-f1f4-47f2-9d54-65e3587de8ed",
   "metadata": {},
   "source": [
    "Let's create a new `conda` environment called \"q-env\" and running Python 3.10:\n",
    "\n",
    "```bash\n",
    "conda create -n q-env python=3.10 -y\n",
    "```\n",
    "\n",
    "After the activation\n",
    "\n",
    "```bash\n",
    "conda activate q-env\n",
    "```\n",
    "\n",
    "start by upgrading `pip` and `ipykernel` via:\n",
    "\n",
    "```bash\n",
    "pip install --upgrade pip ipykernel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09162d4f-6688-4110-ab5e-51e03ac69724",
   "metadata": {},
   "source": [
    "Continue by installing TensorFlow 2.14 (with cuDNN 8.7 and CUDA 11.8):\n",
    "\n",
    "```bash\n",
    "pip install tensorflow[and-cuda]==2.14\n",
    "```\n",
    "\n",
    "Test that the installation succeeds and that TensorFlow correctly accesses the GPU by executing what follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788bdb43-eda6-487d-af64-7de8aba8f62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 20:52:49.464568: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-06-10 20:52:49.464624: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-06-10 20:52:49.464648: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-06-10 20:52:49.472189: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-10 20:52:51.399218: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] TensorFlow version 2.14.0\n",
      "[STATUS] GPU not available\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-10 20:52:54.379316: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-10 20:52:54.427821: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(f\"[DEBUG] TensorFlow version {tf.__version__}\")\n",
    "\n",
    "devices = tf.config.list_physical_devices(\"GPU\")\n",
    "if len(devices) > 0:\n",
    "    rnd = tf.random.uniform(shape=(100, 1))\n",
    "    print(\"[STATUS] GPU available\")\n",
    "else:\n",
    "    print(\"[STATUS] GPU not available\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47d757a-40a1-46b2-bee0-4f1dd07e3ed3",
   "metadata": {},
   "source": [
    "Continue by installing PyTorch 2.1 based on CUDA 11.8:\n",
    "\n",
    "```bash\n",
    "pip install torch==2.1 --index-url https://download.pytorch.org/whl/cu118\n",
    "```\n",
    "\n",
    "Test that the installation succeeds and that PyTorch correctly accesses the GPU by executing what follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de5aa37a-ce53-4764-a7a4-f87ce07734fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] PyTorch version 2.1.0+cu118\n",
      "[STATUS] GPU available\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"[DEBUG] PyTorch version {torch.__version__}\")\n",
    "\n",
    "torch.cuda.init()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    torch.cuda.set_device(device)\n",
    "    rnd = torch.randn(size=(100, 1)).to(device)\n",
    "    print(\"[STATUS] GPU available\")\n",
    "else:\n",
    "    print(\"[STATUS] GPU not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c54168-c6d2-418b-ac34-7e08072da1b4",
   "metadata": {},
   "source": [
    "Continue by installing Jax based on CUDA 11.8 (locally preinstalled):\n",
    "\n",
    "```bash\n",
    "pip install --upgrade \"jax[cuda11_pip]==0.4.25\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "```\n",
    "\n",
    "Test that the installation succeeds and that Jax correctly accesses the GPU by executing what follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f85031c-18fa-4609-994c-78cf01124b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Jax version 0.4.25\n",
      "[STATUS] GPU available\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "print(f\"[DEBUG] Jax version {jax.__version__}\")\n",
    "\n",
    "def jax_has_gpu():\n",
    "    try:\n",
    "        _ = jax.device_put(jax.numpy.ones(1), device=jax.devices('gpu')[0])\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "if jax_has_gpu():\n",
    "    print(\"[STATUS] GPU available\")\n",
    "else:\n",
    "    print(\"[STATUS] GPU not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21702d08-7e62-4d03-82d4-e93381053c0c",
   "metadata": {},
   "source": [
    "Continue by installing Pennylane Lightning with GPU-acceleration:\n",
    "\n",
    "```bash\n",
    "pip install --upgrade pennylane pennylane-lightning pennylane-lightning-gpu\n",
    "```\n",
    "\n",
    "Once installed, you can try to enable the CUDA 11 variant of the NVIDIA cuQuantum custatevec library via `pip`:\n",
    "\n",
    "```bash\n",
    "pip install nvidia-cusparse-cu11 nvidia-cublas-cu11 nvidia-cuda-runtime-cu11 custatevec-cu11\n",
    "```\n",
    "\n",
    "Test that the installation succeeds and that Pennylane Lightning correctly accesses the GPU by executing what follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27ddcf2b-81cd-4055-b039-a86a3b0006d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] PennyLane version 0.36.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/envs/q-cu11.8/lib/python3.10/site-packages/pennylane_lightning/lightning_gpu/lightning_gpu.py:94: UserWarning: libcudart.so.12: cannot open shared object file: No such file or directory\n",
      "  warn(str(e), UserWarning)\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Pre-compiled binaries for lightning.gpu are not available. To manually compile from source, follow the instructions at https://pennylane-lightning.readthedocs.io/en/latest/installation.html.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpennylane\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mqml\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] PennyLane version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqml\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m dev \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlightning.gpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;129m@qml\u001b[39m\u001b[38;5;241m.\u001b[39mqnode(dev)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcircuit\u001b[39m():\n\u001b[1;32m      9\u001b[0m   qml\u001b[38;5;241m.\u001b[39mHadamard(wires\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/envs/q-cu11.8/lib/python3.10/site-packages/pennylane/__init__.py:393\u001b[0m, in \u001b[0;36mdevice\u001b[0;34m(name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DeviceError(\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m plugin requires PennyLane versions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin_device_class\u001b[38;5;241m.\u001b[39mpennylane_requires\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhowever PennyLane version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m     )\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# Construct the device\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m dev \u001b[38;5;241m=\u001b[39m \u001b[43mplugin_device_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# Once the device is constructed, we set its custom expansion function if\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# any custom decompositions were specified.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m custom_decomps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/envs/q-cu11.8/lib/python3.10/site-packages/pennylane_lightning/lightning_gpu/lightning_gpu.py:254\u001b[0m, in \u001b[0;36mLightningGPU.__init__\u001b[0;34m(self, wires, mpi, mpi_buf_size, sync, c_dtype, shots, batch_obs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported complex type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mc_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mwires\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshots\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshots\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dp \u001b[38;5;241m=\u001b[39m DevPool()\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mpi:\n",
      "File \u001b[0;32m/envs/q-cu11.8/lib/python3.10/site-packages/pennylane_lightning/core/lightning_base.py:74\u001b[0m, in \u001b[0;36mLightningBase.__init__\u001b[0;34m(self, wires, c_dtype, shots, batch_obs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     67\u001b[0m     wires,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     71\u001b[0m     batch_obs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m ):\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_CPP_BINARY_AVAILABLE:\n\u001b[0;32m---> 74\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     75\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPre-compiled binaries for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshort_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m are not available. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     76\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo manually compile from source, follow the instructions at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://pennylane-lightning.readthedocs.io/en/latest/installation.html.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         )\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m c_dtype \u001b[38;5;129;01mis\u001b[39;00m np\u001b[38;5;241m.\u001b[39mcomplex64:\n\u001b[1;32m     80\u001b[0m         r_dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat32\n",
      "\u001b[0;31mImportError\u001b[0m: Pre-compiled binaries for lightning.gpu are not available. To manually compile from source, follow the instructions at https://pennylane-lightning.readthedocs.io/en/latest/installation.html."
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "\n",
    "print(f\"[DEBUG] PennyLane version {qml.__version__}\")\n",
    "\n",
    "dev = qml.device(\"lightning.gpu\", wires=2)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit():\n",
    "  qml.Hadamard(wires=0)\n",
    "  qml.CNOT(wires=[0,1])\n",
    "  return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "circuit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfdc1a0-7407-4a04-ad1e-53a040addcfc",
   "metadata": {},
   "source": [
    "Continue by installing Qiskit Aer with GPU-acceleration (based on CUDA 11):\n",
    "\n",
    "```bash\n",
    "pip install qiskit qiskit-aer-gpu-cu11\n",
    "```\n",
    "\n",
    "Test that the installation succeeds and that Qiskit Aer correctly accesses the GPU by executing what follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b161958-4f63-494b-b491-cfbe94b8b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Qiskit version 1.0.2\n",
      "[DEBUG] Counts(ideal): {'000': 488, '111': 536}\n"
     ]
    }
   ],
   "source": [
    "import qiskit\n",
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "print(f\"[DEBUG] Qiskit version {qiskit.__version__}\")\n",
    "\n",
    "# Generate 3-qubit GHZ state\n",
    "circ = qiskit.QuantumCircuit(3)\n",
    "circ.h(0)\n",
    "circ.cx(0, 1)\n",
    "circ.cx(1, 2)\n",
    "circ.measure_all()\n",
    "\n",
    "# Construct an ideal simulator\n",
    "aersim = AerSimulator()\n",
    "\n",
    "# Perform an ideal simulation\n",
    "result_ideal = aersim.run(circ).result()\n",
    "counts_ideal = result_ideal.get_counts(0)\n",
    "print('[DEBUG] Counts(ideal):', counts_ideal)\n",
    "# Counts(ideal): {'000': 493, '111': 531}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502c8e3-000c-41e8-ba8c-1b6c87494861",
   "metadata": {},
   "source": [
    "Finally, continue by installing Qibo, QiboJIT, and CuPy via `conda`:\n",
    "\n",
    "```bash\n",
    "conda install qibo qibojit cupy\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffb86568-42c7-4155-b0e4-eb8aa183b880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] CuPy version 13.0.0\n",
      "[STATUS] GPU available\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "print(f\"[DEBUG] CuPy version {cp.__version__}\")\n",
    "\n",
    "n_cuda_devices = cp.cuda.runtime.getDeviceCount()\n",
    "\n",
    "if n_cuda_devices > 0:\n",
    "    x = cp.array([1, 2, 3])\n",
    "    x.device\n",
    "    print(\"[STATUS] GPU available\")\n",
    "else:\n",
    "    print(\"[STATUS] GPU not available\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q-cu11.8",
   "language": "python",
   "name": "q-cu11.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
