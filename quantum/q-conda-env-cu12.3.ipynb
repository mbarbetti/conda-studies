{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61cdba29-88bc-4208-952c-0c388cc280db",
   "metadata": {},
   "source": [
    "# Quantum `conda` environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8fa78a-f1f4-47f2-9d54-65e3587de8ed",
   "metadata": {},
   "source": [
    "Let's create a new `conda` environment called \"q-env\" and running Python 3.11:\n",
    "\n",
    "```bash\n",
    "conda create -n q-env python=3.11 -y\n",
    "```\n",
    "\n",
    "After the activation\n",
    "\n",
    "```bash\n",
    "conda activate q-env\n",
    "```\n",
    "\n",
    "start by upgrading `pip`, `ipykernel`, and `numpy` via:\n",
    "\n",
    "```bash\n",
    "pip install --upgrade pip ipykernel numpy==1.26.4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09162d4f-6688-4110-ab5e-51e03ac69724",
   "metadata": {},
   "source": [
    "Continue by installing TensorFlow 2.16 (with CUDA 12.3 and cuDNN 8.9):\n",
    "\n",
    "```bash\n",
    "pip install tensorflow[and-cuda]==2.16.*\n",
    "```\n",
    "\n",
    "The next step is to configure the system paths. You can do it with the following command every time you start a new terminal (or Jupyter session) after activating your conda environment:\n",
    "\n",
    "```bash\n",
    "NVIDIA_DIR=$(dirname $(dirname $(python -c \"import nvidia.cudnn;print(nvidia.cudnn.__file__)\")))\n",
    "\n",
    "export LD_LIBRARY_PATH=${CONDA_PREFIX}/lib/:${LD_LIBRARY_PATH}\n",
    "for dir in $(ls -1d $NVIDIA_DIR/*/); do\n",
    "    if [ -d \"${dir}lib\" ]; then\n",
    "        export LD_LIBRARY_PATH=\"${dir}lib:$LD_LIBRARY_PATH\"\n",
    "        if [[ $(basename $dir) == 'cuda_nvcc' ]] ; then\n",
    "            export PATH=\"${dir}bin:$PATH\"\n",
    "        fi\n",
    "    fi\n",
    "done\n",
    "\n",
    "export XLA_FLAGS=--xla_gpu_cuda_data_dir=${CONDA_PREFIX}/lib\n",
    "```\n",
    "\n",
    "For your convenience, it is recommended that you automate it by adding the previous lines in the `env_vars.sh` file as described in the following:\n",
    "\n",
    "```bash\n",
    "mkdir -p $CONDA_PREFIX/etc/conda/activate.d\n",
    "vim $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh\n",
    "```\n",
    "\n",
    "Test that the installation succeeds and that TensorFlow correctly accesses the GPU by executing what follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "788bdb43-eda6-487d-af64-7de8aba8f62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 08:19:41.230856: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-25 08:19:43.334133: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] TensorFlow version 2.16.1\n",
      "[DEBUG] Keras version 3.3.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-25 08:19:46.380799: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 08:19:46.452155: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 08:19:46.454545: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 08:19:46.460717: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 08:19:46.462112: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 08:19:46.463413: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 08:19:46.596927: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 08:19:46.598306: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 08:19:46.599636: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-06-25 08:19:46.600883: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 8098 MB memory:  -> device: 0, name: NVIDIA A100 80GB PCIe MIG 1g.10gb, pci bus id: 0000:00:05.0, compute capability: 8.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[STATUS] GPU available\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "\n",
    "print(f\"[DEBUG] TensorFlow version {tf.__version__}\")\n",
    "print(f\"[DEBUG] Keras version {k.__version__}\")\n",
    "\n",
    "devices = tf.config.list_physical_devices(\"GPU\")\n",
    "if len(devices) > 0:\n",
    "    rnd = tf.random.uniform(shape=(100, 1))\n",
    "    print(\"[STATUS] GPU available\")\n",
    "else:\n",
    "    print(\"[STATUS] GPU not available\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c54168-c6d2-418b-ac34-7e08072da1b4",
   "metadata": {},
   "source": [
    "Continue by installing Jax based on CUDA 12.3 (locally preinstalled):\n",
    "\n",
    "```bash\n",
    "pip install --upgrade \"jax[cuda12_local]==0.4.28\" -f https://storage.googleapis.com/jax-releases/jax_cuda_releases.html\n",
    "```\n",
    "\n",
    "and Flax (via `pip` channel):\n",
    "\n",
    "```bash\n",
    "pip install flax\n",
    "```\n",
    "\n",
    "Test that the installation succeeds and that Jax correctly accesses the GPU by executing what follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f85031c-18fa-4609-994c-78cf01124b02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Jax version 0.4.28\n",
      "[DEBUG] Flax version 0.8.4\n",
      "[STATUS] GPU available\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import flax\n",
    "\n",
    "print(f\"[DEBUG] Jax version {jax.__version__}\")\n",
    "print(f\"[DEBUG] Flax version {flax.__version__}\")\n",
    "\n",
    "def jax_has_gpu():\n",
    "    try:\n",
    "        _ = jax.device_put(jax.numpy.ones(1), device=jax.devices('gpu')[0])\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "if jax_has_gpu():\n",
    "    print(\"[STATUS] GPU available\")\n",
    "else:\n",
    "    print(\"[STATUS] GPU not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21702d08-7e62-4d03-82d4-e93381053c0c",
   "metadata": {},
   "source": [
    "Continue by installing Pennylane Lightning with GPU-acceleration:\n",
    "\n",
    "```bash\n",
    "pip install pennylane pennylane-lightning-gpu\n",
    "```\n",
    "\n",
    "To install Lightning with NVIDIA CUDA support, the following packages need to be installed via `pip`:\n",
    "\n",
    "```bash\n",
    "pip install nvidia-cusparse-cu12 nvidia-cublas-cu12 nvidia-cuda-runtime-cu12 custatevec-cu12\n",
    "```\n",
    "\n",
    "<!--\n",
    "Lightning-GPU requires also the cuQuantum SDK that can be installed by using `conda`:\n",
    "\n",
    "```bash\n",
    "conda install -c conda-forge cuquantum-python cuda-version=12.3 -y\n",
    "```\n",
    "\n",
    "within the Python environment site-packages directory using pip or conda or the SDK library path appended to the LD_LIBRARY_PATH environment variable. Please see the cuQuantum SDK install guide for more information.\n",
    "\n",
    "```bash\n",
    "echo 'export CUQUANTUM_ROOT=${CONDA_PREFIX}' >> $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh\n",
    "\n",
    "source $CONDA_PREFIX/etc/conda/activate.d/env_vars.sh\n",
    "```\n",
    "-->\n",
    "\n",
    "Test that the installation succeeds and that Pennylane Lightning correctly accesses the GPU by executing what follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27ddcf2b-81cd-4055-b039-a86a3b0006d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] PennyLane version 0.36.0\n"
     ]
    },
    {
     "ename": "LightningException",
     "evalue": "[/project/pennylane_lightning/core/src/simulators/lightning_gpu/utils/cuStateVec_helpers.hpp][Line:101][Method:make_shared_cusv_handle]: Error in PennyLane Lightning: custatevec memory allocation failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLightningException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpennylane\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mqml\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[DEBUG] PennyLane version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqml\u001b[38;5;241m.\u001b[39m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m dev \u001b[38;5;241m=\u001b[39m \u001b[43mqml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlightning.gpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwires\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;129m@qml\u001b[39m\u001b[38;5;241m.\u001b[39mqnode(dev)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcircuit\u001b[39m():\n\u001b[1;32m      9\u001b[0m   qml\u001b[38;5;241m.\u001b[39mHadamard(wires\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/envs/q-jax-tf216/lib/python3.11/site-packages/pennylane/__init__.py:393\u001b[0m, in \u001b[0;36mdevice\u001b[0;34m(name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DeviceError(\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m plugin requires PennyLane versions \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mplugin_device_class\u001b[38;5;241m.\u001b[39mpennylane_requires\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhowever PennyLane version \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m__version__\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is installed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m     )\n\u001b[1;32m    392\u001b[0m \u001b[38;5;66;03m# Construct the device\u001b[39;00m\n\u001b[0;32m--> 393\u001b[0m dev \u001b[38;5;241m=\u001b[39m \u001b[43mplugin_device_class\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;66;03m# Once the device is constructed, we set its custom expansion function if\u001b[39;00m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# any custom decompositions were specified.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m custom_decomps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/envs/q-jax-tf216/lib/python3.11/site-packages/pennylane_lightning/lightning_gpu/lightning_gpu.py:261\u001b[0m, in \u001b[0;36mLightningGPU.__init__\u001b[0;34m(self, wires, mpi, mpi_buf_size, sync, c_dtype, shots, batch_obs)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mpi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_local_wires \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_wires\n\u001b[0;32m--> 261\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gpu_state \u001b[38;5;241m=\u001b[39m \u001b[43m_gpu_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc_dtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_local_wires\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mpi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mLightningException\u001b[0m: [/project/pennylane_lightning/core/src/simulators/lightning_gpu/utils/cuStateVec_helpers.hpp][Line:101][Method:make_shared_cusv_handle]: Error in PennyLane Lightning: custatevec memory allocation failed"
     ]
    }
   ],
   "source": [
    "import pennylane as qml\n",
    "\n",
    "print(f\"[DEBUG] PennyLane version {qml.__version__}\")\n",
    "\n",
    "dev = qml.device(\"lightning.gpu\", wires=2)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def circuit():\n",
    "  qml.Hadamard(wires=0)\n",
    "  qml.CNOT(wires=[0,1])\n",
    "  return qml.expval(qml.PauliZ(0))\n",
    "\n",
    "try:\n",
    "    print(\"[DEBUG] Circuit:\", circuit())\n",
    "    # Circuit: 0.0\n",
    "    print(\"[STATUS] GPU available\")\n",
    "except:\n",
    "    print(\"[STATUS] GPU not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dfdc1a0-7407-4a04-ad1e-53a040addcfc",
   "metadata": {},
   "source": [
    "Continue by installing Qiskit Aer with GPU-acceleration (based on CUDA 12):\n",
    "\n",
    "```bash\n",
    "pip install qiskit qiskit-aer-gpu\n",
    "```\n",
    "\n",
    "Test that the installation succeeds and that Qiskit Aer correctly accesses the GPU by executing what follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b161958-4f63-494b-b491-cfbe94b8b583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Qiskit version 1.1.0\n",
      "[DEBUG] Counts(ideal): {'111': 497, '000': 527}\n",
      "[STATUS] GPU available\n"
     ]
    }
   ],
   "source": [
    "import qiskit\n",
    "from qiskit_aer import AerSimulator\n",
    "\n",
    "print(f\"[DEBUG] Qiskit version {qiskit.__version__}\")\n",
    "\n",
    "# Generate 3-qubit GHZ state\n",
    "circ = qiskit.QuantumCircuit(3)\n",
    "circ.h(0)\n",
    "circ.cx(0, 1)\n",
    "circ.cx(1, 2)\n",
    "circ.measure_all()\n",
    "\n",
    "# Construct an ideal simulator\n",
    "aersim = AerSimulator()\n",
    "\n",
    "# Perform an ideal simulation\n",
    "try:\n",
    "    result_ideal = aersim.run(circ).result()\n",
    "    counts_ideal = result_ideal.get_counts(0)\n",
    "    print('[DEBUG] Counts(ideal):', counts_ideal)\n",
    "    # Counts(ideal): {'000': 493, '111': 531}\n",
    "    print(\"[STATUS] GPU available\")\n",
    "except:\n",
    "    print(\"[STATUS] GPU not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7502c8e3-000c-41e8-ba8c-1b6c87494861",
   "metadata": {},
   "source": [
    "Finally, continue by installing Qibo, QiboJIT, and CuPy via `conda`:\n",
    "\n",
    "```bash\n",
    "conda install qibo qibojit -y\n",
    "conda install -c conda-forge cupy cuda-version=12.3 -y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffb86568-42c7-4155-b0e4-eb8aa183b880",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/envs/q-jax-tf216/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] CuPy version 13.2.0\n",
      "[STATUS] GPU available\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "print(f\"[DEBUG] CuPy version {cp.__version__}\")\n",
    "\n",
    "n_cuda_devices = cp.cuda.runtime.getDeviceCount()\n",
    "\n",
    "if n_cuda_devices > 0:\n",
    "    x = cp.array([1, 2, 3])\n",
    "    x.device\n",
    "    print(\"[STATUS] GPU available\")\n",
    "else:\n",
    "    print(\"[STATUS] GPU not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e17337e-6200-4e1d-86cf-627c238babde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "q-jax-tf216",
   "language": "python",
   "name": "q-jax-tf216"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
